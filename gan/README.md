# Generative adversarial networks
GANs are a class of unsupervised models that are commonly used for generating images. No labels are needed to train a GAN, and the loss is generated using just the input image.

GANs have an advantage of VAEs in that the images generated are more realistic and of a higher quality. In addition, GANs allows for interpolation between two generated images. 

However, GANs are slower to train, and trickier. GANs are prone to overfitting, or generating only a single type of image when unable to learn a multimodal distribution.

## Architecture
GANs consist of a **generator** and a **discriminator** network.

<p align="center">
	<img alt="Overall architecture of GANs"
		 src="https://skymind.ai/images/wiki/GANs.png" />
</p>

### Generator
The purpose of the generator network is to convert random input noise into realistic images. In this architecture, the generator takes in a vector (1-D tensor) of randomly generated noise.

_Fully-connected layers_ are used to convert the input vector into a specific number of neurons, and the resultant vector is reshaped into a 2-D tensor representing an image.

_Transposed convolutional layers_ are then used to increase the size of the image, with the final layer typically have 1 or 3 filters, which correspond to the number of image channels.

### Discriminator
The discriminator network aims to distinguish genuine images from fake images generated by the generator.

The discriminator is very much like a typical convolutional neural network. It takes in an input image of shape `[H, W, C]`, and uses convolutional and fully-connected layers to produce an output. In this case, the output is a single neuron with sigmoid activation. The value of this neuron signifies the probability that an image is genuine.

### Additional notes
The model makes heavy use of dropout and batch normalization for regularization. In addition, leaky ReLU is used as the activation function between layers as opposed to the default ReLU to avoid the dying ReLU problem.

## Training
During training, we use two kinds of inputs: a vector of randomly generated noise, and a sample genuine image. The noise vector is fed into the generator to produce an image, `G`. Both `G` and the genuine image are then fed into the discriminator, which produces predictions for both.

The generator loss function minimizes the binary cross entropy between the predictions for `G` and `1.0`. This means that the generator will learn to produce images that cause the discriminator to classify it as genuine.

The discriminator loss function minimizes the binary cross entropy between the predictions for the genuine image and `1.0`, as well as the binary cross entropy between `G` and `0.0`. This means it learns to correctly identify the images as real or fake.

### Dos and don'ts
Backpropagation for the generator and discriminator network variables should be done separately, or the model will not yield proper results.

It was found that using `tf.nn.sigmoid_cross_entropy_with_logits` often yielded blank or noisy results. Using a custom implementation of binary cross entropy with an additional `eps` value to the `tf.log` function rectified the issue. This can thus be attributed to a NaN error when taking the log of zero.

### Maybes
Here are a list of things that can be done to modify the network, without any significant effect on the results of the model. As such, these can also be used to finetune the model.

1. Using batch normalization before leaky ReLU instead of after
1. Modifying the amount of decay in batch normalization
1. Changing the dimensionality of the input noise
1. Adding L2 weight regularization
1. Running the training steps for both generator and discriminator network with the same inputs

## Resources
* [TensorFlow implementation of DCGAN on MNIST](https://github.com/znxlwm/tensorflow-MNIST-GAN-DCGAN/blob/master/tensorflow_MNIST_DCGAN.py)  
Resizes input MNIST images to `64x64` and uses 16x upsampling in generator network.

* [Another TensorFlow implementation of DCGAN on MNIST](https://github.com/ytakzk/Mnist-DCGAN-for-Tensorflow/blob/master/dcgan.ipynb)  
Loss function is more straightforward

* [Blog post for MNIST DCGAN as well](https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c)  